{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def read(dataset, path = \".\"):\n",
    "    if dataset is \"training\":\n",
    "        file_image = os.path.join(path, 'mnist_new-patterns-idx3-ubyte')\n",
    "        file_label = os.path.join(path, 'mnist_new-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        file_image = os.path.join(path, 'mnist_new_test-patterns-idx3-ubyte')\n",
    "        file_label = os.path.join(path, 'mnist_new_test-labels-idx1-ubyte')\n",
    "    elif dataset is \"testall\":\n",
    "        file_image = os.path.join(path, 'mnist_new_testall-patterns-idx3-ubyte')\n",
    "    else:\n",
    "        raise Exception(\"Invalid dataset name\")\n",
    "\n",
    "    with open(file_label, 'rb') as file:\n",
    "        magic, num = struct.unpack(\">II\", file.read(8))\n",
    "        label = np.fromfile(file, dtype=np.int8)\n",
    "\n",
    "    with open(file_image, 'rb') as file:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        image = np.fromfile(file, dtype=np.uint8).reshape(len(label), rows, cols)\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        yield (image[i], label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(read(\"training\"))\n",
    "test_data = list(read(\"testing\"))\n",
    "\n",
    "X_train = np.array(list(zip(*train_data))[0])\n",
    "y_train = np.array(list(zip(*train_data))[1])\n",
    "X_test = np.array(list(zip(*test_data))[0])\n",
    "y_test = np.array(list(zip(*test_data))[1])\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "def load(name):\n",
    "    with open(name, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "X_train_haar = load(\"X_train_haar\")\n",
    "X_test_haar = load(\"X_test_haar\")\n",
    "X_train_reg = load(\"X_train_reg\")\n",
    "X_test_reg = load(\"X_test_reg\")\n",
    "X_train_merge = load(\"X_train_merge\")\n",
    "X_test_merge = load(\"X_test_merge\")\n",
    "X_train_final = load(\"X_train_final\")\n",
    "X_test_final = load(\"X_test_final\")\n",
    "X_train_final_std = load(\"X_train_final_std\")\n",
    "X_test_final_std = load(\"X_test_final_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from time import time\n",
    "import warnings\n",
    "class CustomSVM(BaseEstimator, ClassifierMixin):  \n",
    "    def __init__(self, max_iter=10000, C=1.0, eta=0.01, batch_size=1, tol=1e-6):\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.tol = tol\n",
    "        self.ws_ = None\n",
    "        self.labels_ = None\n",
    "        assert (type(self.max_iter) is int and self.max_iter > 0), \"max_iter must be a positive integer\"\n",
    "        assert (type(self.C) is int or type(self.C) is float), \"C parameter must be an integer or a float\"      \n",
    "        assert (type(self.eta) is int or type(self.eta) is float), \"Eta parameter must be an integer or a float\"      \n",
    "        assert (type(self.batch_size) is int and self.batch_size > 0), \"batch_size must be a positive integer\"\n",
    "        assert (type(self.tol) is int or type(self.tol) is float or tol is None), \"Tolerance must be an integer or a float or None\"\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if X.shape[0] < self.batch_size:\n",
    "            self.batch_size = X.shape[0]\n",
    "            warnings.warn(\"Batch size is bigger than the number of samples. It will be adjusted to the number of samples\")\n",
    "        self.ws_ = None\n",
    "        self.labels_ = np.unique(y)\n",
    "        for label in self.labels_:\n",
    "            w_ = self.sub_fit(X, y, label)\n",
    "            if self.ws_ is None:\n",
    "                self.ws_ = np.append([label], w_)\n",
    "            else:\n",
    "                self.ws_ = np.vstack((self.ws_, np.append([label], w_)))\n",
    "        return self\n",
    "    \n",
    "    def sub_fit(self, X, y, target_label):\n",
    "        y = np.where(y == target_label, 1, -1)\n",
    "        rgen = np.random.RandomState(int(time()))\n",
    "        w_ = rgen.normal(loc=0.0, scale=1, size=1 + X.shape[1])\n",
    "        for a in range(self.max_iter):\n",
    "            step = self.eta * self.batch_grad(X, y, w_)\n",
    "            w_ -= step\n",
    "            if self.tol is not None and np.sum(step / w_) ** 2 < self.tol:\n",
    "                break\n",
    "        return w_\n",
    "    \n",
    "    def batch_grad(self, X, y, w_):\n",
    "        idxs = np.random.choice(y.shape[0], self.batch_size, replace=False)\n",
    "        mat = 1 - np.multiply(self.net_input(X[idxs], w_), y[idxs])\n",
    "        pos_idxs = idxs[np.argwhere(mat >= 0).ravel()]\n",
    "        gd_sumb = np.sum(-y[pos_idxs])\n",
    "        gd_sumw = np.dot(X[pos_idxs].T, -y[pos_idxs]) + pos_idxs.size * w_[1:] / self.C\n",
    "        return np.append(gd_sumb, gd_sumw) / self.batch_size\n",
    "        \n",
    "    def net_input(self, X, w_):\n",
    "        return np.dot(X, w_[1:]) + w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert (self.ws_ is not None and self.labels_ is not None), \"Estimator must be fit before prediction\"\n",
    "        return self.labels_[np.argmax(self.net_input(X, self.ws_[:, 1:].T), axis=1)]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return sum(self.predict(X) == y) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def test_classifier(clf, X_train, y_train, X_test, y_test, C=10.0, eta=0.01, max_iter=50000, batch_size=1000, tol=None):\n",
    "    inst = clf(C=C, eta=eta, max_iter=max_iter, batch_size=batch_size, tol=tol)\n",
    "    start = time()\n",
    "    inst.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    train_accuracy = inst.score(X_train, y_train)\n",
    "    test_accuracy = inst.score(X_test, y_test)\n",
    "    print(clf.__name__)\n",
    "    print(\"Elapsed Time : %d min %d sec\" % ((end-start) // 60, (end-start) % 60))\n",
    "    print(\"Train accuracy : %f\" % train_accuracy)\n",
    "    print(\"Test accuracy : %f \\n\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentumSVM(CustomSVM):  \n",
    "    def __init__(self, max_iter=10000, C=1.0, eta=0.01, batch_size=1, momentum=0.9, tol=1e-6):\n",
    "        super().__init__(max_iter=max_iter, C=C, eta=eta, batch_size=batch_size, tol=tol)\n",
    "        self.momentum = momentum\n",
    "        assert (type(self.momentum) is int or type(self.momentum) is float), \"Momentum term must be an integer or a float\"\n",
    "    \n",
    "    def sub_fit(self, X, y, target_label):\n",
    "        y = np.where(y == target_label, 1, -1)\n",
    "        rgen = np.random.RandomState(int(time()))\n",
    "        w_ = rgen.normal(loc=0.0, scale=1, size=1 + X.shape[1])\n",
    "        before = np.zeros((X.shape[1] + 1, ))\n",
    "        for a in range(self.max_iter):\n",
    "            before = self.momentum * before + self.eta * self.batch_grad(X, y, w_)\n",
    "            w_ -= before\n",
    "            if self.tol is not None and np.sum(before / w_) ** 2 < self.tol:\n",
    "                break\n",
    "        return w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAGSVM(CustomSVM):  \n",
    "    def __init__(self, max_iter=10000, C=1.0, eta=0.01, batch_size=1, momentum=0.9, tol=1e-6):\n",
    "        super().__init__(max_iter=max_iter, C=C, eta=eta, batch_size=batch_size, tol=tol)\n",
    "        self.momentum = momentum\n",
    "        assert (type(self.momentum) is int or type(self.momentum) is float), \"Momentum term must be an integer or a float\"\n",
    "    \n",
    "    def sub_fit(self, X, y, target_label):\n",
    "        y = np.where(y == target_label, 1, -1)\n",
    "        rgen = np.random.RandomState(int(time()))\n",
    "        w_ = rgen.normal(loc=0.0, scale=1, size=1 + X.shape[1])\n",
    "        before = np.zeros((X.shape[1] + 1, ))\n",
    "        for a in range(self.max_iter):\n",
    "            before = self.momentum * before + self.eta * self.batch_grad(X, y, w_)\n",
    "            w_ -= before\n",
    "            if self.tol is not None and np.sum(before / w_) ** 2 < self.tol:\n",
    "                break\n",
    "        return w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class RMSPropSVM(CustomSVM):  \n",
    "    def __init__(self, max_iter=10000, C=1.0, eta=0.01, batch_size=1, momentum=0.9, epsilon=10**-6, tol=1e-6):\n",
    "        super().__init__(max_iter=max_iter, C=C, eta=eta, batch_size=batch_size, tol=tol)\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        assert (type(self.momentum) is int or type(self.momentum) is float), \"Momentum term must be an integer or a float\"\n",
    "        assert (type(self.epsilon) is int or type(self.epsilon) is float), \"Epsilon must be an integer or a float\"\n",
    "    \n",
    "    def sub_fit(self, X, y, target_label):\n",
    "        y = np.where(y == target_label, 1, -1)\n",
    "        rgen = np.random.RandomState(int(time()))\n",
    "        w_ = rgen.normal(loc=0.0, scale=1, size=1 + X.shape[1])\n",
    "        g_ = np.full((X.shape[1] + 1,), 1, dtype=float)\n",
    "        for a in range(self.max_iter):\n",
    "            grad = self.batch_grad(X, y, w_)\n",
    "            g_ = self.momentum * g_ + (1 - self.momentum) * grad ** 2\n",
    "            step = self.eta / np.sqrt(g_ + self.epsilon) * grad\n",
    "            w_ -= step\n",
    "            if self.tol is not None and np.sum(step / w_) ** 2 < self.tol:\n",
    "                break\n",
    "        return w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class AdaDeltaSVM(CustomSVM):  \n",
    "    def __init__(self, max_iter=10000, C=1.0, eta=0.01, batch_size=1, momentum=0.9, epsilon=10**-6, tol=1e-6):\n",
    "        super().__init__(max_iter=max_iter, C=C, eta=eta, batch_size=batch_size, tol=tol)\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "        assert (type(self.momentum) is int or type(self.momentum) is float), \"Momentum term must be an integer or a float\"\n",
    "        assert (type(self.epsilon) is int or type(self.epsilon) is float), \"Epsilon must be an integer or a float\"\n",
    "    \n",
    "    def sub_fit(self, X, y, target_label):\n",
    "        y = np.where(y == target_label, 1, -1)\n",
    "        rgen = np.random.RandomState(int(time()))\n",
    "        w_ = rgen.normal(loc=0.0, scale=1, size=1 + X.shape[1])\n",
    "        g_ = np.full((X.shape[1] + 1,), 1, dtype=float)\n",
    "        s_ = np.full((X.shape[1] + 1,), self.eta**2, dtype=float)\n",
    "        for a in range(self.max_iter):\n",
    "            grad = self.batch_grad(X, y, w_)\n",
    "            g_ = self.momentum * g_ + (1 - self.momentum) * grad ** 2\n",
    "            delta = np.sqrt(s_ + self.epsilon) / np.sqrt(g_ + self.epsilon) * grad\n",
    "            w_ -= delta\n",
    "            s_ = self.momentum * s_ + (1 - self.momentum) * delta ** 2\n",
    "            if self.tol is not None and np.sum(delta / w_) ** 2 < self.tol:\n",
    "                break\n",
    "        return w_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def patchify(X, window, stride, transform=False):\n",
    "    if transform:\n",
    "        sqrt = np.sqrt(X.shape[1])\n",
    "        sqrt = int(sqrt)\n",
    "        X = X.reshape(X.shape[0], sqrt, sqrt)\n",
    "    else:\n",
    "        sqrt = X.shape[1]\n",
    "    window_row, window_col = window\n",
    "    stride_row, stride_col = stride\n",
    "    new_row = (sqrt - window_row) / stride_row + 1\n",
    "    new_col = (sqrt - window_col) / stride_col + 1\n",
    "    data_size = X.itemsize\n",
    "    assert(int(new_row) == new_row and int(new_col) and new_col)\n",
    "    new_row = int(new_row)\n",
    "    new_col = int(new_col)\n",
    "    patchified = np.lib.stride_tricks.as_strided(X, (X.shape[0], new_row, new_col, window_row, window_col), \\\n",
    "                                    (data_size*sqrt*sqrt, data_size*sqrt*stride_row, data_size*stride_col, data_size*sqrt, data_size))\n",
    "    patchified = patchified.reshape(-1, new_row*new_col, window_row, window_col)\n",
    "    return patchified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaarTransformer:\n",
    "    mask1 = np.array([[0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1]])\n",
    "    mask2 = np.array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                      [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                      [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                      [1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "    mask3 = np.array([[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0, 0, 0]])\n",
    "    mask4 = np.array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                      [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "    mask5 = np.array([[0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                      [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                      [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                      [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                      [1, 1, 1, 1, 0, 0, 0, 0]])\n",
    "    masks = (mask1, mask2, mask3, mask4, mask5)\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_mask(mat, mask):\n",
    "        white = sum(mat[mask==1]) / mask[mask==1].size\n",
    "        mask = np.where(mask == 1, 0, 1)\n",
    "        black = sum(mat[mask==1]) / mask[mask==1].size\n",
    "        return abs(white - black)\n",
    "    \n",
    "    @staticmethod\n",
    "    def transform(X):\n",
    "        X = X.reshape(X.shape[0], 28, 28)\n",
    "        result = [[HaarTransformer.apply_mask(X[i][row:row+8, col:col+8], mask) \\\n",
    "                  for mask in HaarTransformer.masks for row in range(0, 21, 4) for col in range(0, 21, 4)] for i in range(X.shape[0])] \n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "class LinearApproximator:\n",
    "    @staticmethod\n",
    "    def regression(mat):\n",
    "        cords = np.argwhere(mat != 0)\n",
    "        if len(cords) == 0:\n",
    "            return 0, 0\n",
    "        xs = cords[:, 0].reshape(1, -1).T\n",
    "        ys = cords[:, 0]\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(xs, ys)\n",
    "        return reg.coef_, reg.intercept_\n",
    "    \n",
    "    @staticmethod\n",
    "    def transform(X):\n",
    "        X = X.reshape(X.shape[0], 28, 28)\n",
    "        result = [[t for row in range(0, 21, 4) for col in range(0, 21, 4) \\\n",
    "                  for t in LinearApproximator.regression(X[i][row:row+8, col:col+8])] for i in range(X.shape[0])] \n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Centralizer:\n",
    "    @staticmethod\n",
    "    def v_centralize(mat):\n",
    "        h_sum = mat.sum(axis=1)\n",
    "        nonzero_rows = np.argwhere(h_sum != 0).ravel()\n",
    "        top_padding = nonzero_rows[0] \n",
    "        bottom_padding = 28 - nonzero_rows[nonzero_rows.size-1]\n",
    "        if abs(top_padding - bottom_padding) > 1:\n",
    "            move = (top_padding + bottom_padding) // 2 - top_padding\n",
    "            return np.roll(mat, move, axis=0)\n",
    "        else:\n",
    "            return mat\n",
    "        \n",
    "    @staticmethod\n",
    "    def h_centralize(mat):\n",
    "        v_sum = mat.sum(axis=0)\n",
    "        nonzero_cols = np.argwhere(v_sum != 0).ravel()\n",
    "        left_padding = nonzero_cols[0] \n",
    "        right_padding = 28 - nonzero_cols[nonzero_cols.size-1]\n",
    "        if abs(left_padding - right_padding) > 1:\n",
    "            move = (left_padding + right_padding) // 2 - left_padding\n",
    "            return np.roll(mat, move, axis=1)\n",
    "        else:\n",
    "            return mat\n",
    "    @staticmethod\n",
    "    def centralize(mat):\n",
    "        return Centralizer.h_centralize(Centralizer.v_centralize(mat))\n",
    "        \n",
    "    @staticmethod\n",
    "    def transform(X):\n",
    "        X = X.reshape(X.shape[0], 28, 28)\n",
    "        return np.array([Centralizer.centralize(mat) for mat in X]).reshape(X.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def rbf_features(X, gamma=0.22):\n",
    "    return [t for idx in range(X.size) if (idx+1) % 6 != 0 and 36 - idx % 36 > 6 \\\n",
    "            for t in (math.exp(-gamma * (X[idx] - X[idx+1]) ** 2), \\\n",
    "                      math.exp(-gamma * (X[idx] - X[idx+6]) ** 2), \\\n",
    "                      math.exp(-gamma * (X[idx] - X[idx+7]) ** 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time for centralization : 0 min 5 sec\n",
      "Elapsed Time for Haar transformation : 7 min 4 sec\n",
      "Elapsed Time for linear approximation : 11 min 1 sec\n",
      "Elapsed Time for adding rbf features : 0 min 46 sec\n",
      "(60000, 777)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "start = time()\n",
    "X_train_centralized = Centralizer.transform(X_train)\n",
    "X_test_centralized = Centralizer.transform(X_test)\n",
    "end = time()\n",
    "print(\"Elapsed Time for centralization : %d min %d sec\" % ((end-start) // 60, (end-start) % 60))\n",
    "\n",
    "start = time()\n",
    "X_train_haar = HaarTransformer.transform(X_train_centralized)\n",
    "X_test_haar = HaarTransformer.transform(X_test_centralized)\n",
    "end = time()\n",
    "print(\"Elapsed Time for Haar transformation : %d min %d sec\" % ((end-start) // 60, (end-start) % 60))\n",
    "\n",
    "start = time()\n",
    "X_train_reg = LinearApproximator.transform(X_train_centralized)\n",
    "X_test_reg = LinearApproximator.transform(X_test_centralized)\n",
    "end = time()\n",
    "print(\"Elapsed Time for linear approximation : %d min %d sec\" % ((end-start) // 60, (end-start) % 60))\n",
    "\n",
    "X_train_merge = np.hstack((X_train_haar, X_train_reg))\n",
    "X_test_merge = np.hstack((X_test_haar, X_test_reg))\n",
    "\n",
    "start = time()\n",
    "rbfs_train = np.array([rbf_features(X) for X in X_train_merge])\n",
    "rbfs_test = np.array([rbf_features(X) for X in X_test_merge])\n",
    "end = time()\n",
    "print(\"Elapsed Time for adding rbf features : %d min %d sec\" % ((end-start) // 60, (end-start) % 60))\n",
    "\n",
    "X_train_final = np.hstack((X_train_merge, rbfs_train))\n",
    "X_test_final = np.hstack((X_test_merge, rbfs_test))\n",
    "print(X_train_final.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_final)\n",
    "X_train_final_std = scaler.transform(X_train_final)\n",
    "X_test_final_std = scaler.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train_haar = load(\"X_train_haar\")\\nX_test_haar = load(\"X_test_haar\")\\nX_train_reg = load(\"X_train_reg\")\\nX_test_reg = load(\"X_test_reg\")\\nX_train_merge = load(\"X_train_merge\")\\nX_test_merge = load(\"X_test_merge\")\\nX_train_final = load(\"X_train_final\")\\nX_test_final = load(\"X_test_final\")\\nX_train_final_std = load(\"X_train_final_std\")\\nX_test_final_std = load(\"X_test_final_std\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "def dump(arr ,name):\n",
    "    with open(name, \"wb\") as file:\n",
    "        pickle.dump(arr, file)\n",
    "\n",
    "dump(X_train_haar, \"X_train_haar\")\n",
    "dump(X_test_haar, \"X_test_haar\")\n",
    "dump(X_train_reg, \"X_train_reg\")\n",
    "dump(X_test_reg, \"X_test_reg\")\n",
    "dump(X_train_merge, \"X_train_merge\")\n",
    "dump(X_test_merge, \"X_test_merge\")\n",
    "dump(X_train_final, \"X_train_final\")\n",
    "dump(X_test_final, \"X_test_final\")\n",
    "dump(X_train_final_std, \"X_train_final_std\")\n",
    "dump(X_test_final_std, \"X_test_final_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomSVM\n",
      "Elapsed Time : 14 min 50 sec\n",
      "Train accuracy : 0.946883\n",
      "Test accuracy : 0.937700 \n",
      "\n",
      "MomentumSVM\n",
      "Elapsed Time : 14 min 24 sec\n",
      "Train accuracy : 0.955583\n",
      "Test accuracy : 0.949400 \n",
      "\n",
      "NAGSVM\n",
      "Elapsed Time : 14 min 19 sec\n",
      "Train accuracy : 0.956033\n",
      "Test accuracy : 0.948200 \n",
      "\n",
      "RMSPropSVM\n",
      "Elapsed Time : 14 min 29 sec\n",
      "Train accuracy : 0.934067\n",
      "Test accuracy : 0.929900 \n",
      "\n",
      "AdaDeltaSVM\n",
      "Elapsed Time : 14 min 36 sec\n",
      "Train accuracy : 0.951617\n",
      "Test accuracy : 0.943600 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(CustomSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=20000, batch_size=500)\n",
    "test_classifier(MomentumSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=20000, batch_size=500)\n",
    "test_classifier(NAGSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=20000, batch_size=500)\n",
    "test_classifier(RMSPropSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=20000, batch_size=500)\n",
    "test_classifier(AdaDeltaSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=20000, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomSVM\n",
      "Elapsed Time : 26 min 54 sec\n",
      "Train accuracy : 0.953983\n",
      "Test accuracy : 0.945600 \n",
      "\n",
      "MomentumSVM\n",
      "Elapsed Time : 26 min 43 sec\n",
      "Train accuracy : 0.955600\n",
      "Test accuracy : 0.949800 \n",
      "\n",
      "NAGSVM\n",
      "Elapsed Time : 26 min 39 sec\n",
      "Train accuracy : 0.955483\n",
      "Test accuracy : 0.950400 \n",
      "\n",
      "RMSPropSVM\n",
      "Elapsed Time : 26 min 42 sec\n",
      "Train accuracy : 0.940967\n",
      "Test accuracy : 0.934500 \n",
      "\n",
      "AdaDeltaSVM\n",
      "Elapsed Time : 26 min 48 sec\n",
      "Train accuracy : 0.952350\n",
      "Test accuracy : 0.945400 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(CustomSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700)\n",
    "test_classifier(MomentumSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700)\n",
    "test_classifier(NAGSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700)\n",
    "test_classifier(RMSPropSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700)\n",
    "test_classifier(AdaDeltaSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomSVM\n",
      "Elapsed Time : 2 min 26 sec\n",
      "Train accuracy : 0.585167\n",
      "Test accuracy : 0.588500 \n",
      "\n",
      "MomentumSVM\n",
      "Elapsed Time : 9 min 53 sec\n",
      "Train accuracy : 0.945833\n",
      "Test accuracy : 0.938700 \n",
      "\n",
      "NAGSVM\n",
      "Elapsed Time : 12 min 25 sec\n",
      "Train accuracy : 0.949717\n",
      "Test accuracy : 0.943600 \n",
      "\n",
      "RMSPropSVM\n",
      "Elapsed Time : 21 min 40 sec\n",
      "Train accuracy : 0.942000\n",
      "Test accuracy : 0.934300 \n",
      "\n",
      "AdaDeltaSVM\n",
      "Elapsed Time : 21 min 43 sec\n",
      "Train accuracy : 0.531083\n",
      "Test accuracy : 0.520300 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(CustomSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-7)\n",
    "test_classifier(MomentumSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-7)\n",
    "test_classifier(NAGSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-7)\n",
    "test_classifier(RMSPropSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-7)\n",
    "test_classifier(AdaDeltaSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomSVM\n",
      "Elapsed Time : 5 min 50 sec\n",
      "Train accuracy : 0.565517\n",
      "Test accuracy : 0.558700 \n",
      "\n",
      "MomentumSVM\n",
      "Elapsed Time : 22 min 51 sec\n",
      "Train accuracy : 0.956450\n",
      "Test accuracy : 0.949800 \n",
      "\n",
      "NAGSVM\n",
      "Elapsed Time : 16 min 46 sec\n",
      "Train accuracy : 0.953733\n",
      "Test accuracy : 0.946300 \n",
      "\n",
      "RMSPropSVM\n",
      "Elapsed Time : 21 min 42 sec\n",
      "Train accuracy : 0.943333\n",
      "Test accuracy : 0.937300 \n",
      "\n",
      "AdaDeltaSVM\n",
      "Elapsed Time : 24 min 57 sec\n",
      "Train accuracy : 0.953150\n",
      "Test accuracy : 0.946800 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(CustomSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-8)\n",
    "test_classifier(MomentumSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-8)\n",
    "test_classifier(NAGSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-8)\n",
    "test_classifier(RMSPropSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-8)\n",
    "test_classifier(AdaDeltaSVM, X_train_final_std, y_train, X_test_final_std, y_test, max_iter=30000, batch_size=700, tol=1e-8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
